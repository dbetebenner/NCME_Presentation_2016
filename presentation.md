## Student Growth Percentiles
### Damian Betebenner
### _NCME 2016 Washington, DC_

---

### Two Themes to Connect 3 Papers

<p class="fragment">1. Measurement error & SGPs.</p>
<p class="fragment">2. Measures versus Indicators.</p>

===

### Measurement error in scores used for SGP calculation impacts both the accuracy (bias) and precision of SGPs.

#### Measurement error results in a double whammy eroding both the accuracy and precision of estimates.

##### (Carroll, Ruppert & Stefanski, 1995)


===

<p class="fragment">This has been a particular interest of mine since inital SGP development in 2006.</p>
<p class="fragment">Led to a dissertation by Yi Shang (Boston College) on SIMEX measurement error correction.</p>
<p class="fragment">All three papers are concerned with bias/precision issues to some extent.</p>

===

### Measures, measures everywhere ...

- The term _measure_ is used to describe just about every number these days.
- Met Study: "Effective teaching can be measured". Why not: "Effective teaching can be evaluated."
- Stevens: “measurement is the assignment of numerals to objects or events according to rule”.
- See Joel Michell’s _Measurement in Psychology_ (2005) for a critical examination of Steven’s concept and psychological measurement in general.
- Our field has been lax on policing the boundaries of what is (and isn’t) a measure.


===

### Measures versus Indicators

- You say tomato, I say tomato.
- My impression: _measure_ connotes something "scientific" whereas indicator is more _fuzzy_.
- Validating a _measure_ commits one to particular validation tasks.
- How does one validate an _indicator_?
    - Large overlap with validation of measures.
    - Valid indicators are useful (utility).
    - Measures needn't be useful.

===

### Measures versus Indicators

- Big push in educational measurement to increase utility of assessment results even at the expense of desirable technical qualities (e.g. precision).
- Does an indicator need to be a "causal estimator" to be a part of personnel evaluation?
- Maybe indicators are all we've ever had.

<!---
#######################################################################################
### Denbleyker and Lin
#######################################################################################
-->

---

### Evaluating Student Growth Percentiles: Perspective of Test-Retest Reliability

#### Johnny Denbleyker & Ye Lin

===

### Academic Peers

- Report contains LOTS of analyses looking at both accuracy and precision of SGPs
- Will focus on issues related to academic peers.
- Causes the most confusion in explaining SGPs.
- A heuristic meant to avoid using the **R** word: Regression.

===

### Academic Peers

- Academic peers are students with the exact same prior scale score history.
- Regression yields the functional relationship between priors and current scores using all data.
- In practice, students are normed against all students with _at least_ as many priors as them.
- Thus, some students have 1st order SGPs while others have higher order SGPs.

===

### Academic Peers

- In general, no systematic difference between 1st, 2nd, 3rd, ... order groups!
- However, there are instances of where differences exist.
- The group of students with just a single prior were qualitatively different than the students with more priors who they
were normed with.

===

### Questions/Wish list

- With regard to the profile patterns you found, are there other explanations for the differences?
- Your interim assessment data has significant differences in time-lapse. Have you considered conditioning on time-lag in addition to prior scores?


<!---
#######################################################################################
### Furgol Castellano, McCaffrey & Lockwood
#######################################################################################
-->

---

### The Accuracy and Fairness of Aggregate Student Growth Percentiles as Indicators of Student Performance

#### Katherine Furgol Castellano, Daniel McCaffrey, & J.R. Lockwood



===

### Congratulations to Katherine on receiving the 2016 Jason Millman Promising Measurement Scholar Award


===

### SGPs and measurement error

- Some beautiful derivations in the paper. 
- Measurement error in scores used to calculate SGPs leads to bias.
    - Prior and current score measurement error leads to error in SGPs.
    - Non-random assignment of students cluster errors.
- Bias in mSGPs: against lower achieving groups and for higher achieving groups.


===

### mSGPs and Fairness

- Different conceptualizations of Fairness
    - Absence of measurement bias.
    - Absence of differential impact.
- Paper uses the latter but examines differential impact related to measurement bias.
- Is this really "fairness" or just measurement bias.

===

### Questions/Wish list

- How much different would results be if distributional assumptions relaxed?
- Would be great to see an ethically grounded discussion of "fairness" merged with these validation efforts.


<!---
#######################################################################################
### Monroe & Cai
#######################################################################################
-->

---

### Cluster Growth Percentiles: An Alternative to Aggregated Student Growth Percentiles

#### Scott Monroe & Li Cai


===

### Cluster Growth Percentiles (CGP)

- The work with MIRT and SGPs is really phenomenal!
- A group SGP summary that isn't an aggregation of individual SGPs.
- Uses MIRT framework to elegantly deal with measurement error adjusting for bias and providing precision/reliability estimates.
- Importantly: CGPs are uniformly distributed like SGPs.


===

### In search of a reporting scale

- From the initial release of Colorado Growth Model, distribution differences between mSGPs and SGPs
has led to problems in creating labels.
    - Low, Typical, High SGPs had different cuts than mSGP.
    - Easier to motivate group growth with the same cuts.
- Applaud the authors for recognizing the utility of this!


===

### Questions/Wish List

- Are adequate growth percentiles (AGP) supported with the MIRT framework?
    - This would help in establishing criterion-referenced for students.
    - How would those translate to CGP?
- How important are distributional assumptions?
- What is the impact of ceilings/floors?


---

<!---
#######################################################################################
### Summary
#######################################################################################
-->

## Summary

===

### 3 great papers

- Papers all make significant contributions to the understanding of the role the measurement error plays in SGPs and SGP summaries.
- Papers all cognizant of the role of _utility_ which was a primary design criterion in the creation of SGPs.
- Papers all contribute to efforts to use growth data sensibly, especially when used for evaluative purposes.


<!---
#######################################################################################
### References
#######################################################################################
-->

---

## References

##### Carroll, R. J., Ruppert, D., & Stefanski, L. A. (1995). _Measurement error in nonlinear models_. London: Chapman & Hall.

##### Michell, J (2005). _Measurement in Psychology_. New York: Cambridge University Press.
